{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "##### <a href=\"https://colab.research.google.com/github/unt-iialab/INFO5731_Spring2020/blob/master/Assignments/INFO5731_Assignment_Four.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "RvDmCZgqupZD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USSdXHuqnwv9"
      },
      "source": [
        "# **INFO5731 Assignment Four**\n",
        "\n",
        "In this assignment, you are required to conduct topic modeling, sentiment analysis based on **the dataset you created from assignment three**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWxodXh5n4xF"
      },
      "source": [
        "# **Question 1: Topic Modeling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TenBkDJ5n95k"
      },
      "source": [
        "(30 points). This question is designed to help you develop a feel for the way topic modeling works, the connection to the human meanings of documents. Based on the dataset from assignment three, write a python program to **identify the top 10 topics in the dataset**. Before answering this question, please review the materials in lesson 8, especially the code for LDA, LSA, and BERTopic. The following information should be reported:\n",
        "\n",
        "(1) Features (text representation) used for topic modeling.\n",
        "\n",
        "(2) Top 10 clusters for topic modeling.\n",
        "\n",
        "(3) Summarize and describe the topic for each cluster. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xUEI3YktuaKp"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TFxx8E8UuaKq"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "import gensim.corpora as corpora"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dJQODHmHuaKq"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# from pprint import pprint\n",
        "# import gensim\n",
        "# import gensim.corpora as corpora\n",
        "# from gensim.utils import simple_preprocess\n",
        "# from gensim.models import CoherenceModel\n",
        "# import spacy\n",
        "# import pyLDAvis\n",
        "# pyLDAvis.enable_notebook()\n",
        "# import pyLDAvis.gensim_models as gensimvis  # don't skip this\n",
        "# import matplotlib.pyplot as plt\n",
        "# %matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PuFPKhC0m1fd"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n",
        "\n",
        "data = pd.read_csv(\"data_with_sentiment_score.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        },
        "id": "xrzdPN89uaKr",
        "outputId": "2f9668e4-8a9a-4e16-ccc3-798dd8f1763e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Unnamed: 0  Unnamed: 0.1                                title  \\\n",
              "0            0             0                      What's Up, Doc?   \n",
              "1            1             1             Murder on the Blackboard   \n",
              "2            2             2                                 Szél   \n",
              "3            3             3                             The Herd   \n",
              "4            4             4                    It's Now or Never   \n",
              "..         ...           ...                                  ...   \n",
              "95          95            95                  Jailbait Babysitter   \n",
              "96          96            96  Jönssonligan & den svarta diamanten   \n",
              "97          97            97                    Women Without Men   \n",
              "98          98            98                          A War Story   \n",
              "99          99            99                     Manhattan Parade   \n",
              "\n",
              "                                         film_outline  Sentiment Scores  \\\n",
              "0   Two researchers have come to San Francisco to ...           -0.3612   \n",
              "1   There are plenty of guilty secrets at the scho...           -0.7351   \n",
              "2   During a film course lead by Yvette Biro at th...            0.0000   \n",
              "3   Because of a local blood feud, a peasant famil...           -0.9083   \n",
              "4   A lonely sheep farmer in his fifties employs t...            0.7650   \n",
              "..                                                ...               ...   \n",
              "95  Vicki is 17 and her older friends call her Jai...            0.9168   \n",
              "96  Sickan, the leader of the criminal Jönsson gan...           -0.4588   \n",
              "97  Women without men can have lots of fun with ea...            0.9391   \n",
              "98  Major Ben Wheeler was a Canadian doctor assign...           -0.5789   \n",
              "99  The John Roberts Costume Company is being run ...            0.8625   \n",
              "\n",
              "   direction  \n",
              "0   Negative  \n",
              "1   Negative  \n",
              "2    Neutral  \n",
              "3   Negative  \n",
              "4   Positive  \n",
              "..       ...  \n",
              "95  Positive  \n",
              "96  Negative  \n",
              "97  Positive  \n",
              "98  Negative  \n",
              "99  Positive  \n",
              "\n",
              "[100 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3aa30270-e446-4063-a2e0-114974c3f3a8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>title</th>\n",
              "      <th>film_outline</th>\n",
              "      <th>Sentiment Scores</th>\n",
              "      <th>direction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>What's Up, Doc?</td>\n",
              "      <td>Two researchers have come to San Francisco to ...</td>\n",
              "      <td>-0.3612</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Murder on the Blackboard</td>\n",
              "      <td>There are plenty of guilty secrets at the scho...</td>\n",
              "      <td>-0.7351</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>Szél</td>\n",
              "      <td>During a film course lead by Yvette Biro at th...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>The Herd</td>\n",
              "      <td>Because of a local blood feud, a peasant famil...</td>\n",
              "      <td>-0.9083</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>It's Now or Never</td>\n",
              "      <td>A lonely sheep farmer in his fifties employs t...</td>\n",
              "      <td>0.7650</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>95</td>\n",
              "      <td>95</td>\n",
              "      <td>Jailbait Babysitter</td>\n",
              "      <td>Vicki is 17 and her older friends call her Jai...</td>\n",
              "      <td>0.9168</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>96</td>\n",
              "      <td>96</td>\n",
              "      <td>Jönssonligan &amp; den svarta diamanten</td>\n",
              "      <td>Sickan, the leader of the criminal Jönsson gan...</td>\n",
              "      <td>-0.4588</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>97</td>\n",
              "      <td>97</td>\n",
              "      <td>Women Without Men</td>\n",
              "      <td>Women without men can have lots of fun with ea...</td>\n",
              "      <td>0.9391</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>98</td>\n",
              "      <td>98</td>\n",
              "      <td>A War Story</td>\n",
              "      <td>Major Ben Wheeler was a Canadian doctor assign...</td>\n",
              "      <td>-0.5789</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>99</td>\n",
              "      <td>99</td>\n",
              "      <td>Manhattan Parade</td>\n",
              "      <td>The John Roberts Costume Company is being run ...</td>\n",
              "      <td>0.8625</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3aa30270-e446-4063-a2e0-114974c3f3a8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3aa30270-e446-4063-a2e0-114974c3f3a8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3aa30270-e446-4063-a2e0-114974c3f3a8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "RSGpkVjauaKs"
      },
      "outputs": [],
      "source": [
        "total_text = data.film_outline.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "OPQXEhcLuaKs"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "SDF8afvWuaKs"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"wordnet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZkgb2z2xkQu",
        "outputId": "b3228617-7f51-4638-f935-40b56a18ac21"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "t_vYW2vguaKs"
      },
      "outputs": [],
      "source": [
        "stop_words_list = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "oAV8mV0cuaKs"
      },
      "outputs": [],
      "source": [
        "tokenized_text_list = []\n",
        "for each_text_item in total_text:\n",
        "    tokenized_text = word_tokenize(each_text_item)\n",
        "    tokenized_text_list.append(tokenized_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "BZkE9j6uuaKs"
      },
      "outputs": [],
      "source": [
        "stop_words_removed_list = []\n",
        "for each_text_item in tokenized_text_list:\n",
        "    stop_words_removed_text = [word for word in each_text_item if not word.lower() in stop_words_list]\n",
        "    stop_words_removed_list.append(stop_words_removed_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ZQqR1qXkuaKt"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "KOFykYGpuaKt"
      },
      "outputs": [],
      "source": [
        "# import these modules\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "  \n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gL5C94KfuaKt",
        "outputId": "7b04bd1f-b6f2-48e3-b2b5-5811fc4c0591"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "nltk.download('omw-1.4')\n",
        "lemm_text_list = []\n",
        "for each_text_item in stop_words_removed_list:\n",
        "    lemm_text = []\n",
        "    for each_word in each_text_item:\n",
        "        lemm_text.append(lemmatizer.lemmatize(each_word))\n",
        "    lemm_text_list.append(lemm_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "zrrT2uRMuaKt"
      },
      "outputs": [],
      "source": [
        "id2word = corpora.Dictionary(lemm_text_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "hc_uIJWWuaKt"
      },
      "outputs": [],
      "source": [
        "corpus = [id2word.doc2bow(text) for text in lemm_text_list]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "PkhrodSWuaKt"
      },
      "outputs": [],
      "source": [
        "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
        "                                           id2word=id2word,\n",
        "                                           num_topics=20, \n",
        "                                           random_state=100,\n",
        "                                           update_every=1,\n",
        "                                           chunksize=100,\n",
        "                                           passes=10,\n",
        "                                           alpha='auto',\n",
        "                                           per_word_topics=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "8OX8tMnRuaKu"
      },
      "outputs": [],
      "source": [
        "doc_lda = lda_model[corpus]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erNoT_ixuaKu",
        "outputId": "4c8c96f4-8d6a-48cb-fa2a-cd8a50239f4f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0,\n",
              "  '0.017*\",\" + 0.012*\"former\" + 0.012*\"hustler\" + 0.012*\".\" + 0.006*\"football\" + 0.006*\"get\" + 0.006*\"abandon\" + 0.006*\"partner\" + 0.006*\"come\" + 0.006*\"plan\"'),\n",
              " (1,\n",
              "  '0.087*\",\" + 0.056*\".\" + 0.025*\"\\'s\" + 0.006*\"family\" + 0.005*\"husband\" + 0.005*\"young\" + 0.005*\"return\" + 0.004*\"friend\" + 0.004*\"year\" + 0.004*\"Zelda\"'),\n",
              " (2,\n",
              "  '0.036*\".\" + 0.032*\",\" + 0.027*\"(\" + 0.027*\")\" + 0.016*\"Takashi\" + 0.010*\"city\" + 0.010*\"Mustafa\" + 0.010*\"house\" + 0.008*\"\\'s\" + 0.008*\"Earth\"'),\n",
              " (3,\n",
              "  '0.037*\".\" + 0.033*\",\" + 0.015*\"de\" + 0.008*\")\" + 0.008*\"(\" + 0.008*\"Police\" + 0.008*\"gay\" + 0.008*\"Benson\" + 0.008*\"Marquis\" + 0.008*\"Scaramouche\"'),\n",
              " (4,\n",
              "  '0.001*\",\" + 0.001*\".\" + 0.001*\"Frankie\" + 0.000*\"Carol\" + 0.000*\"\\'s\" + 0.000*\"(\" + 0.000*\"Robert\" + 0.000*\"home\" + 0.000*\")\" + 0.000*\"child\"'),\n",
              " (5,\n",
              "  '0.030*\",\" + 0.030*\".\" + 0.017*\"infected\" + 0.017*\"herd\" + 0.013*\"find\" + 0.009*\"cow\" + 0.009*\"Wheeler\" + 0.009*\"brand\" + 0.009*\"Gene\" + 0.009*\"ship\"'),\n",
              " (6,\n",
              "  '0.041*\",\" + 0.033*\".\" + 0.011*\")\" + 0.011*\"Andre\" + 0.011*\"(\" + 0.011*\"Johanna\" + 0.011*\"Dario\" + 0.008*\"car\" + 0.008*\"covered\" + 0.008*\"jungle\"'),\n",
              " (7,\n",
              "  '0.031*\".\" + 0.024*\",\" + 0.017*\"Vicki\" + 0.011*\"\\'s\" + 0.011*\"business\" + 0.011*\"Lorraine\" + 0.011*\"\\'\\'\" + 0.011*\"``\" + 0.007*\"$\" + 0.007*\"movie\"'),\n",
              " (8,\n",
              "  '0.056*\",\" + 0.032*\".\" + 0.016*\"\\'s\" + 0.016*\"\\'\\'\" + 0.013*\"Dot\" + 0.013*\"Cutey\" + 0.010*\"``\" + 0.008*\"marry\" + 0.008*\"one\" + 0.006*\"\\'\"'),\n",
              " (9,\n",
              "  '0.030*\",\" + 0.025*\".\" + 0.010*\"murder\" + 0.010*\"book\" + 0.010*\"New\" + 0.010*\"Marie\" + 0.005*\"\\'s\" + 0.005*\"find\" + 0.005*\"writer\" + 0.005*\"time\"'),\n",
              " (10,\n",
              "  '0.000*\",\" + 0.000*\".\" + 0.000*\"Sam\" + 0.000*\"covered\" + 0.000*\"circus\" + 0.000*\"car\" + 0.000*\"Wonder\" + 0.000*\"Kitty\" + 0.000*\"ensues\" + 0.000*\"Donald\"'),\n",
              " (11,\n",
              "  '0.049*\".\" + 0.012*\"film\" + 0.012*\"Kara\" + 0.008*\",\" + 0.008*\"like\" + 0.008*\"director\" + 0.008*\"-\" + 0.008*\"treasure\" + 0.004*\"peak\" + 0.004*\"requirement\"'),\n",
              " (12,\n",
              "  '0.054*\",\" + 0.052*\".\" + 0.013*\"find\" + 0.012*\"\\'s\" + 0.008*\"stranger\" + 0.008*\"alien\" + 0.008*\"without\" + 0.008*\"Questor\" + 0.008*\"fun\" + 0.008*\"Vaslovik\"'),\n",
              " (13,\n",
              "  '0.083*\",\" + 0.061*\".\" + 0.014*\"\\'s\" + 0.006*\"Wayne\" + 0.006*\")\" + 0.006*\"(\" + 0.005*\"Conrad\" + 0.005*\"Sam\" + 0.005*\"circus\" + 0.005*\"-\"'),\n",
              " (14,\n",
              "  '0.059*\",\" + 0.047*\".\" + 0.016*\"\\'s\" + 0.009*\"Cooke\" + 0.009*\"life\" + 0.009*\"Shep\" + 0.007*\"wife\" + 0.007*\"become\" + 0.007*\"top\" + 0.007*\"stolen\"'),\n",
              " (15,\n",
              "  '0.028*\".\" + 0.028*\";\" + 0.016*\",\" + 0.012*\"Playboy\" + 0.012*\"shot\" + 0.008*\"game\" + 0.008*\"ground\" + 0.008*\"playing\" + 0.008*\"Grotto\" + 0.008*\"first\"'),\n",
              " (16,\n",
              "  '0.026*\",\" + 0.026*\".\" + 0.017*\"Sickan\" + 0.013*\"Inspector\" + 0.009*\"\\'s\" + 0.009*\"(\" + 0.009*\")\" + 0.009*\"Dr\" + 0.009*\"Busé\" + 0.009*\"case\"'),\n",
              " (17,\n",
              "  '0.088*\",\" + 0.051*\".\" + 0.015*\"\\'s\" + 0.014*\"Jimmy\" + 0.013*\"money\" + 0.012*\"Ruth\" + 0.008*\"life\" + 0.007*\")\" + 0.007*\"Roberts\" + 0.007*\"Blackie\"'),\n",
              " (18,\n",
              "  '0.089*\",\" + 0.055*\".\" + 0.014*\"\\'s\" + 0.007*\"Ramon\" + 0.006*\"love\" + 0.006*\"Kitchell\" + 0.006*\"woman\" + 0.005*\"find\" + 0.005*\"young\" + 0.005*\"blackmail\"'),\n",
              " (19,\n",
              "  '0.083*\",\" + 0.045*\".\" + 0.022*\"Frankie\" + 0.013*\"Carol\" + 0.012*\"\\'s\" + 0.011*\"Tom\" + 0.007*\"film\" + 0.007*\"Charley\" + 0.007*\"Marshal\" + 0.007*\"go\"')]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "lda_model.print_topics()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfpMRCrRwN6Z"
      },
      "source": [
        "# **Question 2: Sentiment Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dCQEbDawWCw"
      },
      "source": [
        "(30 points). Sentiment analysis also known as opinion mining is a sub field within Natural Language Processing (NLP) that builds machine learning algorithms to classify a text according to the sentimental polarities of opinions it contains, e.g., positive, negative, neutral. The purpose of this question is to develop a machine learning classifier for sentiment analysis. Based on the dataset from assignment three, write a python program to implement a sentiment classifier and evaluate its performance. Notice: **80% data for training and 20% data for testing**.  \n",
        "\n",
        "(1) Features used for sentiment classification and explain why you select these features.\n",
        "\n",
        "(2) Select two of the supervised learning algorithm from scikit-learn library: https://scikit-learn.org/stable/supervised_learning.html#supervised-learning, to build a sentiment classifier respectively. Note: Cross-validation (5-fold or 10-fold) should be conducted. Here is the reference of cross-validation: https://scikit-learn.org/stable/modules/cross_validation.html.\n",
        "\n",
        "(3) Compare the performance over accuracy, precision, recall, and F1 score for the two algorithms you selected. Here is the reference of how to calculate these metrics: https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "prTOJkY5uaKv"
      },
      "outputs": [],
      "source": [
        "data_with_sentiment = pd.read_csv(\"data_with_sentiment_score.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "O8kFFjpEuaKv"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "zS1ed7FUuaKv"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "kKafbjk7uaKv"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "b9XubJPAuaKv"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "Ukbp_ObIuaKv"
      },
      "outputs": [],
      "source": [
        "X = vectorizer.fit_transform(data_with_sentiment['film_outline'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ox6jQK4ZuaKv",
        "outputId": "c5a1bcd3-a5e7-4949-b230-0738b04e4dc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 2883)\n"
          ]
        }
      ],
      "source": [
        "print(X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "UcnPdnkJuaKv"
      },
      "outputs": [],
      "source": [
        "y = data_with_sentiment['direction']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "ZdztijoquaKv"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "waTxtAfAuaKw"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "xHOviqXYuaKw"
      },
      "outputs": [],
      "source": [
        "Ada_clf = AdaBoostClassifier(n_estimators=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "w_k5Zsb7uaKw"
      },
      "outputs": [],
      "source": [
        "acc_scores_1 = cross_val_score(Ada_clf, X_train, y_train, cv=5, scoring = 'accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBwF1TaIuaKw",
        "outputId": "4effb190-e8c8-4202-dc00-30dce8e702cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.510989010989011"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "acc_scores_1.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "W7Kruz5wuaKw"
      },
      "outputs": [],
      "source": [
        "from sklearn import tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "R-xfGtbxuaKw"
      },
      "outputs": [],
      "source": [
        "DT_clf = tree.DecisionTreeClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "m4VNCvyUuaKw"
      },
      "outputs": [],
      "source": [
        "acc_scores_2 = cross_val_score(DT_clf, X_train, y_train, cv=5, scoring = 'accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDVUwyhpuaKw",
        "outputId": "12e839cf-59de-4552-d6d3-2bb3fca2db62"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.510989010989011"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "acc_scores_2.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5mmYIfN8eYV"
      },
      "source": [
        "# **Question 3: House price prediction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsi2y4z88ngX"
      },
      "source": [
        "(40 points). You are required to build a **regression** model to predict the house price with 79 explanatory variables describing (almost) every aspect of residential homes. The purpose of this question is to practice regression analysis, an supervised learning model. The training data, testing data, and data description files can be download from canvas. Here is an axample for implementation: https://towardsdatascience.com/linear-regression-in-python-predict-the-bay-areas-home-price-5c91c8378878. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "-tVvhOGxuaKx"
      },
      "outputs": [],
      "source": [
        "house_data_train = pd.read_csv(\"train.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "cxwEl7BKuaKx"
      },
      "outputs": [],
      "source": [
        "X = house_data_train.iloc[:,:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "eTJRURrCuaKx"
      },
      "outputs": [],
      "source": [
        "X = X.fillna(\"Not avaiable\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "cA9TtJ54uaKx"
      },
      "outputs": [],
      "source": [
        "X = pd.get_dummies(X, dummy_na=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "ciV2zgeJuaKx"
      },
      "outputs": [],
      "source": [
        "y = house_data_train.iloc[:,-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "1KgXa57WuaKx"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "db0yRABCuaKx"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "rXbLPPZxuaKx"
      },
      "outputs": [],
      "source": [
        "gdb_regressor = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1,\n",
        "                                max_depth=1, random_state=0,loss='squared_error').fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WC0poDk4uaKx",
        "outputId": "b219ce19-64ab-47f6-ad6a-1c69b25ef9d1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdaBoostClassifier(n_estimators=100)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "Ada_clf.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "QxwkkxRPuaKy"
      },
      "outputs": [],
      "source": [
        "y_pred = Ada_clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "vwAP2xqbuaKy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}